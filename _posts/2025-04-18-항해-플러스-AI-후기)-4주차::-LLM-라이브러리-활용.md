---
title: 항해 플러스 AI 후기) 4주차 LLM 라이브러리 활용 / 프롬프팅
description: >-
  항해 플러스 AI 과정을 진행하면서 4주차에 학습한 내용을 정리한다.
author: 김가은
date: 2025-04-11 23:00:00 +0900
categories: [항해플러스AI]
tags: [항해99, 항해 플러스 AI 후기, AI 개발자, LLM, 딥러닝, 머신러닝, 인공지능, 자연어 처리, GPT, Hugging Face, 프롬프팅, Prompt, 프롬프팅 기법]
pin: true
---

이번주에는 모델 학습을 쉽게 구현할 수 있게 해주는 HuggingFace library와 GPT를 기반으로 하는 LLM 활용 방법에 대해 학습하였다.

이번주 발제를 시작하기에 앞서, 발제 코치님께서 지난주 멘토링 발제 중 모두에게 공유하면 좋을만한 내용을 다시 한 번 정리해주셨다.
(이 중 내 질문도 있어서 혼자 뿌듯했다😆) 

## 3주차 멘토링 질의응답 추가 공유

#### epoch를 몇으로 설정해야 할까
epoch가 짧으면 모델이 충분히 학습하지 못할 수 있기 때문에, 처음에는 길게 늘려놓는 것이 좋다.
wandb나 mlflow와 같은 실험관리 도구를 통해 어느 지점에서 test 성능이 고점을 찍고 하락하는지 파악할 수 있다.

> 지난주, 이번주 과제를 할 때는 early stopping을 추가하고 epoch를 넉넉하게 설정했다.
> 그럼에도 epochs를 어느 정도로 해야 넉넉한건지 의문이 있었다.
> wandb나 mlflow와 같은 실험관리 도구를 사용하면 훨씬 더 편리할 것 같다.

#### freeze에 대하여
pretrained된 모델은 이미 충분한 자연어 데이터를 가지고 학습한 모델이다.
fine tuning은 pretrained된 모델에 특수한 task로 학습을 시키는 것이기 때문에 출력층과 가까운 레이어들만 학습을 시키는 것이 좋다.
fine tuning에 사용하는 소량의 데이터를 가지고 전체 모델을 학습하면 입력층에 가까운 레이어들에 저장되었던 언어 전반에 대한 지식을 잃어버리게 할 수 있다.
gradual unfreezing을 사용해 출력층에 가까운 레이어부터 단계별로 레이어를 unfreeze하는 방법도 고려할 수 있다.

> 지난 주에 성능이 잘나온다는 이유만으로 freeze를 적용하지 않았는데, freeze를 왜 사용하는지, 언제 사용하는지를 잘 이해하고 사용해야 한다고 반성했다.

#### BERT와 GPT의 차이
LLM은 모델 크기가 매우 커서 실행하는데만 GPU 자원이 매우 많이 필요하다.
반면에 BERT는 모델의 크기가 상대적으로 아주 작아서 LLM으로 풀기에 간단한 자연어처리 문제들을 아주 효율적으로 해결할 수 있다.
한 모델로 다양한 문제를 해결하는게 아니라 한 종류의 문제만 해결하면 될 때, 입력 텍스트가 너무 길지 않을 때, 텍스트 분류나 추천과 같은 task에는 BERT가 더 적합하다.
반면에 텍스트 생성, 요약, 증강과 같이 창의성과 고도화된 언어지식을 통해 문제를 해결해야 하는 경우에는 GPT가 더 적합하다.

> 어떤 모델을 사용하는지도 결국 over engineering 문제라고 생각했다.
> 특히 Closed LLM API를 사용한다면 비용이 중요한 문제이기 때문에 더욱더 이런 부분이 중요한 것 같다.


## 4주차 학습한 내용: LLM 라이브러리 활용

이번 주차에는 모델 학습을 쉽게 구현할 수 있게 해주는 HuggingFace library와 GPT를 기반으로 하는 LLM 활용 방법에 대해 학습하였다.

### 1. HuggingFace Library

HuggingFace는 파이썬 라이브러리 중 하나로 Transformer와 관련된 모델, task, 학습 방법에 대한 구현체들을 제공한다.
https://huggingface.co/

- Text 분류, 기계번역과 같이 입력/출력이 모두 text인 Sequence-to-Sequence, transformer의 자연어 이해 능력을 올리기 위한 pre-training task를 해결하기 위한 다양한 Transformer 구현체들을 제공한다.
https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForNextSentencePrediction
- 다양한 데이터셋을 제공한다.
https://huggingface.co/datasets
- 다양한 pre-trained 모델을 제공한다.
https://huggingface.co/models

#### Trainer
우리가 이전 주차까지 pytorch를 통해 직접 구현한 모델들과 비교해보면 훨씬 더 쉽고 빠르게 모델을 구현할 수 있다.

trainer를 사용해 학습, logging, 평가 등의 과정을 자동으로 수행할 수 있다.

> 과제를 하면서 Trainer를 처음 사용해봤는데, 필요한 옵션들만 설정하면 되서 편하기도 했지만,
> 한편으로는 각각의 option이 어떤 값인지 파악하는데 시간이 걸렸고, 출력 같은 경우에도 내가 원하는 형태로 출력이 되도록 코드를 작성하는게 어려웠다.
> 멘토링 시간에도 코치님이랑 얘기했는데, 오히려 인터페이스가 추상화되어 있어서 처음 사용할 때는 어려운 부분이 있는 것 같다.
> 그래도 코드량도 줄어들고, 코드 구현보다 어떻게 학습시킬지에 집중할 수 있는 것 같아서 좋다.

### 2. LLM

GPT와 같이 pre-training 방식으로 매우 큰 Transformer와 많은 data로 학습한 모델들을 말한다.
next token prediction으로 학습했기 때문에 text 생성이 가능하고, 이를 활용해 다양한 task를 해결할 수 있다.

#### Closed LLM
모델 규모나 학습 data가 공개되지 않으며, 개별적으로 만든 UI나 API를 통해서만 사용이 가능한 LLM을 말한다.
ChatGPT, Gemini, Claude 등이 있다.

#### Open LLM
모델 규모나 학습 data가 공개되어 있어 누구나 사용할 수 있는 LLM을 말한다.
일반적으로 HuggingFace를 통해 공개되어 있어 HuggingFace를 통해 사용할 수 있다.

#### LLM Benchmark
LLM의 성능을 평가하기 위한 지표는 매우 다양하다.
목적에 따라 적합한 지표를 선택해야 한다.
LLM에서 사용하는 대표적인 Benchmark는 다음과 같은 것들이 있다.

**Massive Multi-Task Language Understanding(MMLU)**
특정 도메인보다는 다양한 natural language processing task에 대한 성능을 평가하는 벤치마크이다.
LLM의 범용성을 평가할 수 있다.

**Math**
수학 추론 능력을 평가하기 위한 benchmark이다.

**ZeroSCROLLS**
긴 context에서도 LLM이 잘 작동하는지 확인하는 benchmark이다.

**MGSM**
LLM의 multilingual 성능을 평가하기 위한 benchmark이다.

> 새로운 LLM Model이 나오면 어떤 벤치마크에서 몇 점 혹은 몇 등을 했는지, 다른 어떤 모델과 어떤 차이가 있는지 설명하는걸 볼 수 있다.
> [Gemini 2.5 Flash에 대한 Threads 글](https://www.threads.net/@hon_coding/post/DIkPXBYSKNE?xmt=AQGzQVJo1k5Wd7W91nMcTJG2SyOvKLtr9yHISuu82iALfw&ref=stdy.blog)

### 3. LLM으로 Text Classification 문제 풀기
LLM을 사용해 Text Classification 문제를 풀어보자. 
LLM은 tokenizer의 사전에 있는 모든 token들에 대한 확률 분포, 즉 logit을 계산한다.
이를 활용하면 학습 없이도 분류 문제를 해결할 수 있다.

> LLM은 텍스트를 생성하는데, 질문에 대해 생성한 답으로 분류 문제를 풀 수 있다는 것이 재미있었다.

**Zero Shot Classification**
Zero Shot Classification은 학습된 모델이 특정 태스크에 대해 별도의 추가 학습 없이도 바로 분류 작업을 수행할 수 있는 능력을 말한다. 
예를 들어, LLM이 특정 주제에 대해 학습하지 않았더라도, 주어진 텍스트가 어떤 카테고리에 속하는지 예측할 수 있다.
이는 LLM이 다양한 텍스트 데이터를 학습하면서 얻은 일반적인 언어 이해 능력을 활용하기 때문이다.

**Few Shot Classification**
Few Shot Classification은 모델이 소수의 예시만으로도 새로운 태스크를 학습하고 분류 작업을 수행할 수 있는 능력을 말한다.
예를 들어, LLM에게 몇 개의 예시 문장을 제공하면, 모델은 이를 바탕으로 새로운 문장이 어떤 카테고리에 속하는지 예측할 수 있다.
이는 LLM이 사전 학습을 통해 얻은 지식을 바탕으로, 주어진 예시를 통해 빠르게 새로운 태스크에 적응할 수 있기 때문이다.

### 4. Prompting
같은 문제를 풀어도 LLM이 더 좋은 성능을 내도록 입력을 꾸미는 작업을 말한다.
LLM은 같은 문제라도 어떻게 프롬프팅하냐에 따라 성능에 차이가 크다.
특히 성능이 좋은 LLM의 경우 어떻게 질문을 던져도 잘 답변하지만, open LLM과 같이 성능이 떨어지는 모델을 사용하면 프롬프팅이 매우 중요하다.

[여러가지 프롬프팅 기법을 설명한 참고 논문](https://arxiv.org/pdf/2402.07927)
[Google에서 최근 공개한 Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)

**Chain of Thought(CoT)**
Chain of Thought는 모델이 문제를 해결하기 위해 일련의 논리적 단계를 따라가도록 하는 프롬프팅 기법이다.
대다수의 closed LLM은 CoT를 기본적으로 진행한다.

**Program-aided language model(PAL)**
LLM은 기본적으로 자연어 처리 모델이기 때문에 연산을 수행할 때 오차가 생길 수 있다.
이를 해결하기 위해 수학적 연산을 코드로 풀어서 해결하는 방법이다.
대다수의 closed LLM은 마지막에 "코드를 써서 풀어줘"라는 text만 전달해줘도 출력을 할 때 코딩을 활용하게 된다.

**Retrieval-augmented generation(RAG)**
LLM의 hallucination을 줄이기 위해 사용되는 방법이다.
LLM이 인터넷 검색을 통해 자료를 더 찾아본 뒤에 답변을 작성하도록 하는 방법이다.
RAG를 활용하면 최신 정보를 가지고 답변을 도출하기 때문에 높은 정확도의 답변을 기대할 수 있고, 출처를 같이 알려주기 때문에 거짓말을 검증하는 것이 쉬워져 신뢰도를 계산할 수 있다.

## 이번주 회고: 과제
### 기본과제: MNLI task를 해결하는 모델 만들기
이번주 기본과제는 Trainer를 사용해서 MNLI task를 해결하는 모델을 만드는 것이었다.
MNLI task는 두 문장이 주어졌을 때, 두 문장이 논리적으로 연결되어 있는지, 서로 모순되는지, 무관한지 판단하는 task로,
지난주 심화과제에서 다뤄봤기 때문에 데이터 자체가 낯설지는 않았다.

지난주 심화과제에서는 전체 레이어를 freeze하지 않고 출력층만 학습시킨 경우와, gradual unfreezing을 사용한 경우, freeze를 적용하지 않은 경우를 비교해보았다. [과제 코드](https://github.com/paran22/hanghae_plus_ai_assignment/tree/main/assignment/3-hard)

그런데 freeze를 적용하지 않은 경우에는 굉장히 학습이 빠르게 되고, 과적합 징후도 보여 이번에는 freeze를 적용해서 테스트하였다.

다른 과제 중에 for문을 사용해서 여러 가지 조건을 비교하는 코드를 참고해서, learning rate와 batch size를 여러 가지 조건으로 테스트해보았다. [과제 코드](https://github.com/paran22/hanghae_plus_ai_assignment/blob/main/assignment/4-basic.ipynb)

early stopping을 추가하는 것과, 원하는 형태로 출력을 만드는 부분에서 시간이 오래걸렸다.
그래도 최종적으로는 이렇게 각 설정 별로 그래프와 주요 지표들을 정리해서 추가할 수 있었다.
![스크린샷 2025-04-18 오후 11 33 55](https://github.com/user-attachments/assets/4e93ee39-6025-4b4a-b44f-397bc9161974)


### 심화과제: 수능 국어 문제를 GPT로 풀어보기
심화과제는 수능 국어 문제를 GPT로 풀어보는 것이었다.
목표 점수는 80점이다.

[AI 수능 국어 만점 프로젝트 Github](https://github.com/NomaDamas/KICE_slayer_AI_Korean)에 잘 정리가 되어 있어 이를 참고했다.

처음에 gpt-4를 사용하려고 했는데 지원하지 않는 모델이라고 해서 사용을 못했다(그런데 며칠 뒤에는 되던데 뭐지🥲)
그 다음에 사용한 모델을 gpt-4o였다.
몇 가지 프롬프팅을 조합해서 목표점수는 금방 넘을 수 있었다.

그런데 실시간 Q&A시간에 코치님께서 각각의 프롬프트에 따라서 어떻게 차이가 나는지 비교해보라고 예시 템플릿을 주셨다.
특히 csv 파일로 결과를 저장해서 중복되는 경우에는 csv 파일에 있는 데이터를 불러오는 방식이 좋았다.
프롬프팅 하면서 여러 번 시도를 하게 되는데 이걸 어떻게 비교해야지, 라는 궁금증이 있었는데 템플릿 코드를 참고해서 여러 가지 시도를 해볼 수 있었다. [과제 코드](https://github.com/paran22/hanghae_plus_ai_assignment/blob/main/assignment/4-hard/4-hard.ipynb)

openai api를 사용하면 비용이 나오기 때문에 더 신경쓰였다.

처음에 사용하지 못한 gpt-4도 사용해봤는데, 비용이 너무 많이 나가서 이후에는 사용하지 않았다.
한번 돌렸는데 6달러가 나갔다.😭

gpt-4o나 새로 나온 gpt-4.1이 가격도 훨씬 저렴하고 성능도 좋았다.

시도해본 프롬프팅 중에는 감정적 호소와 역할 부여, COT가 좋은 성능을 보였다.
one shot도 결과는 괜찮았지만, 예시를 넣다보니 다른 프롬프팅에 비해서 사용하는 토큰이 많았다.

가격 효율을 생각하면 one shot보다는 다른 프롬프팅 기법이 좋다고 느껴졌다.

gpt-4o-mini가 굉장히 저렴해서, gpt-4o-mini에 점수가 잘 나온 프롬프팅을 결합해서 사용해봤다.

그렇지만 점수는 오히려 더 낮아지거나 비슷한 결과가 나왔다.

다른 모델에 비해 gpt-4o-mini가 결과를 숫자로 출력하라는 프롬프트도 잘 수행하지 않고 다르게 출력하는 경우가 있었다.

프롬프팅은 다양한 자료가 많은 것 같다.

시간에 쫓겨서 과제를 수행하느라 프롬프팅 기법 하나하나를 비교하면서 수행하지는 못한 것 같다.

### 추가과제: 챗봇 만들기
추가 과제로 챗봇을 구현해보는 과제가 있었다.

cursor를 사용해서 구현해보았는데 구현하는데 30분밖에 안걸렸다.
cursor로 주로 기존 코드를 수정하거나 기능 추가하는데 사용하다가, 이렇게 프로젝트 처음부터 Agent를 사용해서 코드를 구현한 건 처음이었는데 굉장히 만족스러운 결과였다.

처음 프롬프팅으로 챗봇을 만들고, 테스트해보면서 로딩바를 추가한다든지, 채팅 메시지를 한번에 보여주는게 아니라 readable stream을 사용해서 단어별로 출력하도록 수정하였다.

요구한 수정사항도 잘 반영이 되었고, 디자인도 나쁘지 않아서 프로토 타입으로 사용하기에 아주 좋을 것 같다.

이전에 gpt를 사용한 챗봇을 구현해본 적이 있어서 어떤 ui가 좋을지 생각이 분명했기 때문에 더 빨리 구현할 수 있었던 것 같다.
![스크린샷 2025-04-18 오후 11 58 54](https://github.com/user-attachments/assets/82813954-ec65-4a4f-9bb4-425b3a9ee0c1)


---------

곧 프로젝트에 들어간다.
프로젝트 주제를 여러가지로 고민하고 있다.
하고 싶은 주제는 있는데, 모델을 학습시키기 위한 데이터나, 성능을 평가하기 위한 데이터가 부족해서 고민이다.🫠

이번에는 학습 목적으로 학습하기 쉬운, 데이터가 좀 더 분명한 프로젝트를 진행하고,
그 다음에 학습한 내용을 바탕으로 내가 하고싶은 프로젝트를 진행하는 것도 괜찮을 것 같다.

이번주도 재밌었고, 과제를 다 제출한 나에게 박수를 보낸다.👏





































